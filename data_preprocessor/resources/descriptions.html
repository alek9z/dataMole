<html>
<!-- @formatter:off -->
<style>
    table, th, td {
      border: 1px solid black;
    }
    th, td {
      padding: 0.3em;
    }
</style>
<!-- @formatter:on -->
<section name="RangeDiscretizer">
    <h2>RangeDiscretizer</h2>
    Discretize numeric columns into user specified contiguous ranges <br/>
    <b>Input types</b>: Numeric<br/>
    <b>Output types</b>: Ordinal
    <h3>Table options</h3>
    Bin edges can be specified in the "Bin edges" column. Bin edges must be numbers and must be
    separated by a single space. Bin labels must be specified and their number must be exactly the
    number of intervals specified, which is the number of edges -1.
    <br/>
    <em>Example:</em>
    <br/>
    <table>
        <tr>
            <th>Bin edges</th>
            <th>Labels</th>
        </tr>
        <tr>
            <td>1.0 1.5 4 5.1</td>
            <td>Low Medium High</td>
        </tr>
    </table>
    In the example bins are set for intervals: (1.0, 1.5], (1.5, 4.0], (4.0, 5.1]
    <h3>Create new attribute</h3>
    If selected the operation will produce one new column for every attribute to be discretized, and
    each column will have the original name followed by the provided suffix. Notice that if the
    dataframe contains columns with the exact same name of the new columns, these columns will be
    replaced.<br/>
    If the option is selected the original column will not be touched, otherwise it is
    replaced.
</section>
<section name="BinsDiscretizer">
    <h2>BinDiscretizer</h2>
    Discretize a numeric column into a defined number of bins
    <b>Input types</b>: Numeric<br/>
    <b>Output type</b>: Ordinal
    <h3>Table options</h3>
    The number of bins can be specified in column "K".<br/>
    <em>Example:</em>
    <br/>
    <table>
        <tr>
            <th>Column</th>
            <th>Type</th>
            <th>K</th>
        </tr>
        <tr>
            <td>Attribute1</td>
            <td>Numeric</td>
            <td>6</td>
        </tr>
        <tr>
            <td>Attribute2</td>
            <td>Numeric</td>
            <td>9</td>
        </tr>
    </table>
    The above configuration discretize the two attributes with 6 and 9 bins respectively.
    <h3>Strategy</h3>
    <ul>
        <li><b>Uniform</b>: all bins in each feature have identical widths</li>
        <li><b>Quantile</b>: all bins in each feature have the same number of points</li>
        <li><b>Kmeans</b>: all bins in each feature have the same nearest center of a 1D k-means
            cluster
        </li>
    </ul>
    <h3>Create new attribute</h3>
    If selected the operation will produce one new column for every attribute to be discretized, and
    each column will have the original name followed by the provided suffix. Notice that if the
    dataframe contains columns with the exact same name of the new columns, these columns will be
    replaced.<br/>
    If the option is selected the original column will not be touched, otherwise it is
    replaced.
</section>
<section name="DateDiscretizer">
    <h2>DateDiscretizer</h2>
    Discretize a datetime attribute into user specified contiguous ranges, optionally using both date
    and time components.<br/>
    <b>Input types</b>: Datetime<br/>
    <b>Output types</b>: Ordinal
    <h3>Table options</h3>
    Datetime bins can be specified in the "Ranges" column, while "Labels" must contain one string
    label for every attribute type, each separated by a blank space. To use a string with space
    inside the string must be double quoted (")<br/>
    <em>Example:</em>
    <br/>
    <table>
        <tr>
            <th>Column</th>
            <th>Type</th>
            <th>Ranges</th>
            <th>Labels</th>
        </tr>
        <tr>
            <td>Attribute1</td>
            <td>Datetime</td>
            <td>(2000-01-01, 2001-01-01]<br/>(2001-01-01, 2002-01-01]</td>
            <td>00/01 01/02</td>
        </tr>
    </table>
    The above configuration produce one Ordinal attribute with all dates in (2000-01-01, 2001-01-01]
    labelled with "00/01" and all dates in (2001-01-01, 2002-01-01] labelled as "01/02". There is no
    way of excluding an interval from discretization, since all ranges are contiguous. The only way to
    achieve this is by labelling all the unwanted dates with a specific category and then replacing
    all the categories values with NaN using the operation <i>ReplaceValues</i>.
    <h3>Create new attribute</h3>
    If selected the operation will produce one new column for every attribute to be discretized, and
    each column will have the original name followed by the provided suffix. Notice that if the
    dataframe contains columns with the exact same name of the new columns, these columns will be
    replaced.<br/>
    If the option is selected the original column will not be touched, otherwise it is
    replaced.
</section>
<section name="RemoveBijections">
    <h2>RemoveBijections</h2>
    Removes from selection all columns with the same values but with different names.<br/>
    <b>Input types</b>: All<br/>
    <b>Output type</b>: Same
    <h3>Table options</h3>
    Column to consider for removal must be selected in the table. Unchecked columns will not be
    dropped, even if duplicated.
</section>
<section name="ExtractTimeSeries">
    <h2>ExtractTimeSeries</h2>
    Normalizes a dataset containing time series information. <br/>
    <h3>Requirements</h3>
    <h4>Motivation</h4>
    This feature is tailored for longitudinal datasets, which means dataset in this form:
    <table>
        <tr>
            <th>A_wave1</th>
            <th>A_wave2</th>
            <th>A_wave3</th>
            <th>B_wave1</th>
            <th>B_wave2</th>
            <th>B_wave3</th>
        </tr>
        <tr>
            <td>12.1</td>
            <td>12.4</td>
            <td>11.0</td>
            <td>0.10</td>
            <td>1.23</td>
            <td>4.53</td>
        </tr>
    </table>
    In this dataset the same attribute "A" and "B" are measured at different times, but each
    measurement is codified as a different column. This operation allow to obtain a normalised dataset
    that can be visualised with the time series features. It generates a new dataset with this form:
    <table>
        <tr>
            <th>Time</th>
            <th>A</th>
            <th>B</th>
        </tr>
        <tr>
            <td>wave1</td>
            <td>12.1</td>
            <td>0.10</td>
        </tr>
        <tr>
            <td>wave2</td>
            <td>12.4</td>
            <td>1.23</td>
        </tr>
        <tr>
            <td>wave3</td>
            <td>11.0</td>
            <td>4.53</td>
        </tr>
    </table>
    <h4>With ID</h4>
    It's also possible that a measurement is performed at the same time for many individuals. In this
    case every individual must be identifiable by an ID which remains consistent through time. The
    dataset will look like this:
    <table>
        <tr>
            <th>Id</th>
            <th>A_wave1</th>
            <th>A_wave2</th>
            <th>A_wave3</th>
            <th>B_wave1</th>
            <th>B_wave2</th>
            <th>B_wave3</th>
        </tr>
        <tr>
            <td>id1</td>
            <td>12.1</td>
            <td>12.4</td>
            <td>11.0</td>
            <td>0.10</td>
            <td>1.23</td>
            <td>4.53</td>
        </tr>
        <tr>
            <td>id2</td>
            <td>1.02</td>
            <td>12.4</td>
            <td>1.02</td>
            <td>3.45</td>
            <td>2.31</td>
            <td>4.99</td>
        </tr>
    </table>
    In this case this operation can transform the dataset in this fashion:
    <table>
        <tr>
            <th>Id</th>
            <th>Time</th>
            <th>A</th>
            <th>B</th>
        </tr>
        <tr>
            <td>id1</td>
            <td>wave1</td>
            <td>12.1</td>
            <td>0.10</td>
        </tr>
        <tr>
            <td>id1</td>
            <td>wave2</td>
            <td>12.4</td>
            <td>1.23</td>
        </tr>
        <tr>
            <td>id1</td>
            <td>wave3</td>
            <td>11.0</td>
            <td>4.53</td>
        </tr>
        <tr>
            <td>id2</td>
            <td>wave1</td>
            <td>1.02</td>
            <td>3.45</td>
        </tr>
        <tr>
            <td>id2</td>
            <td>wave2</td>
            <td>12.4</td>
            <td>2.31</td>
        </tr>
        <tr>
            <td>id2</td>
            <td>wave2</td>
            <td>1.02</td>
            <td>4.99</td>
        </tr>
    </table>
    <h3>Usage</h3>
    <h4>Table options</h4>
    The first step is the specification of the attributes (series) to create. This must be done in the
    "Series name" table. Then you must define how to create every series: from every relevant dataset
    you must select which attribute represent the time measurements of the series you are building.
    With respect to the previous example (which had only one dataset) for time series "A" you should
    have selected attributes "A_wave1", "A_wave2", "A_wave3" and for series "B" you should have selected
    "B_wave1", "B_wave2", "B_wave3". After this, you must associate every time entry (in this case for
    wave1, wave2 and wave3) with a label, which should be something that easily identifies a time
    point, like a time or a date. To do this we must add to the "Time labels" 3 labels: "wave1",
    "wave2" and "wave3". Be careful! Labels <em>order matters</em>. Labels will be added to an Ordinal
    column, ordered exactly as shown in list. For this reason it's possible to drag labels to reorder
    them as required. After that every selected attribute must be associated with the defined time
    labels. In this example "A_wave1" will be placed at time "wave1", "A_wave2" at time "wave2",
    "B_wave1" at "wave1", "B_wave3" at "wave3" and so on.
</section>
<section name="DropColumns">
    <h2>Drop</h2>
    Remove columns from dataframe<br/>
    <b>Input types</b>: All<br/>
    <b>Output types</b>: Same
    <h3>Table options</h3>
    All selected columns will be removed from dataframe.
</section>
<section name="DuplicateColumn">
    <h2>DuplicateColumn</h2>
    Duplicate dataframe columns<br/>
    <b>Input types</b>: All<br/>
    <b>Output types</b>: Same
    <h3>Table options</h3>
    Select the columns to duplicate and specify their new name. Only non existing column names can be
    used, otherwise an error will be shown.
</section>
<section name="FillNan">
    <h2>FillNan</h2>
    Fill NaN/NaT values over columns with specified method<br/>
    <b>Input types</b>: All<br/>
    <b>Output types</b>: Same
    <h3>Table options</h3>
    Columns to be processed must be selected. The "Fill value" column is relevant only if the selected
    strategy is "Values", in which case it can not be empty.
    <h3>Strategy</h3>
    <ul>
        <li><b>Backfill</b>: fill with next valid observation</li>
        <li><b>Pad</b>: propagate last valid observation forward up to the next one</li>
        <li><b>Mean</b>: fill gaps with the mean of column (only for Numeric and Datetime)</li>
        <li><b>Value</b>: fill gaps in every column with a specified value</li>
    </ul>
</section>
<section name="SetIndex">
    <h2>Set index</h2>
    Set an index to the dataframe<br/>
    <h3>Table options</h3>
    Selected columns will replace the current index column(s). After this, they will not be visible as
    columns, but they can be reinserted in the dataframe with the ResetIndex operation.
</section>
<section name="ResetIndex">
    <h2>Reset index</h2>
    Reset the index of the dataframe. All named index levels will be inserted in the dataframe as
    columns. Unnamed index levels are dropped.
</section>
<section name="Join">
    <h2>Join</h2>
    Join two dataframes on index or columns.
    <h3>Join type</h3>
    Supports all SQL-style join: left, right, inner, outer.
    <h3>Join on index</h3>
    If selected the two dataframes will be joined over their index, which will be preserved. Otherwise
    it's necessary to select one column from both dataframe and the join will be done on those
    columns. In this case the index is not preserved, and a default one will be set.
    <h3>Suffixes</h3>
    If some columns have the same name in both dataframes they will be renamed with these suffixes to
    distinguish them.
</section>
<section name="OneHotEncoder">
    <h2>One-hot encoder</h2>
    Encode categorical or string column as a one-hot array<br/>
    <b>Input types</b>: Categorical, String<br/>
    <b>Output types</b>: Nominal
    <h3>Table options</h3>
    For every selected column a set of new columns will be appended to the dataframe, one for every
    distinct category or string value found in the original column. These columns will have the same
    original name, with the distinct value as suffix. The new columns will have type Nominal
    and will contain binary values.
    <h3>Column for nan</h3>
    Whether to add a column also for NaN values. If selected it is added regardless of the presence of
    NaN values.
</section>
<section name="RemoveNanColumns">
    <h2>RemoveNanColumns</h2>
    Remove columns with NaN values.<br/>
    <b>Input types</b>: All<br/>
    <b>Output types</b>: Same
    <h3>Usage</h3>
    Can operate in one of two modes:
    <ul>
        <li>By removing every column with more than a minimum number of NaN values</li>
        <li>By removing every column with NaN ratio > threshold</li>
    </ul>
</section>
<section name="RemoveNanRows">
    <h2>RemoveNanColumns</h2>
    Remove columns with NaN values.<br/>
    <b>Input types</b>: All<br/>
    <b>Output types</b>: Same
    <h3>Usage</h3>
    Can operate in one of two modes:
    <ul>
        <li>By removing rows with more than a minimum number of NaN values over all columns</li>
        <li>By removing rows with NaN ratio > threshold over all columns</li>
    </ul>
</section>
<section name="RenameColumns">
    <h2>Rename column</h2>
    Rename columns of the dataframe.<br/>
    <b>Input types</b>: All<br/>
    <b>Output types</b>: Same
    <h3>Usage</h3>
    Double click a column name to start editing and insert the new name. All column names should be
    unique.
</section>
<section name="ReplaceValues">
    <h2>Replace values</h2>
    Replace values in dataframe columns.<br/>
    <b>Input types</b>: String, Categorical, Numeric<br/>
    <b>Output types</b>: Same
    <h3>Table options</h3>
    Replace values in the dataframe.
</section>
<section name="MinMaxScaler">
    <h2>Min max scaler</h2>
    Scales columns as
    <code>[(X - X_min) / (X_max - X_min)] * (max - min) + min</code>
    , where <code>X_min</code> and <code>X_max</code> are the column-wise minimum and maximum and
    <code>[min, max]</code> is the specified feature range (inclusive).<br/>
    <b>Input types</b>: Numeric<br/>
    <b>Output types</b>: Numeric
    <h3>Table options</h3>
    All selected columns will be scaled and will replace the original column. If you want to preserve
    the original columns you will need to make a copy of them with the "Duplicate columns"
    operation. <br/>
    The feature range must be for every selected column in the "Range" column as numbers separated by
    a blank space. The decimal separator is set to ".".
</section>
<section name="StandardScaler">
    <h2>Standard scaler</h2>
    Scales column values as (X - &mu;) / &sigma;, with &sigma;=std and &mu;=mean.<br/>
    <b>Input types</b>: Numeric<br/>
    <b>Output types</b>: Numeric
    <h3>Table options</h3>
    All selected columns will be scaled and will replace the original column. If you want to preserve
    the original columns you will need to make a copy of them with the "Duplicate columns"
    operation. No additional options are required.
</section>
<section name="ToNumeric">
    <h2>To numeric</h2>
    Convert columns to Numeric type (floating point).<br/>
    <b>Input types</b>: String, Categorical<br/>
    <b>Output types</b>: Numeric
    <h3>Table options</h3>
    All selected columns will be converted to numeric, if possible. The handling of conversion errors
    depend on the "Error mode" option.
    <h3>Error mode</h3>
    <ul>
        <li><b>Raise</b>: invalid parsing will stop the operation with an error and no column is
            changed
        </li>
        <li><b>Coerce</b>: invalid parsed values will be set as NaN</li>
    </ul>
</section>
<section name="ToCategorical">
    <h2>To categorical</h2>
    Convert columns to Categorical type. This conversion is convenient to encode columns with a small
    set of distinct values. It can also be used to convert between Ordinal and Nominal and to change
    the valid categories.<br/>
    <b>Input types</b>: String, Numeric, Categorical<br/>
    <b>Output types</b>: Ordinal or Nominal
    <h3>Table options</h3>
    Selected columns allow to input the exact categories to be considered, as strings separated by a
    space. During conversion, encountered values which were not specified will be set to NaN. If the
    "Categories" column is left empty, all distinct values will be considered categories.<br/>
    The "Ordered" column controls whether the column will be Nominal (with False) or Ordinal (with
    True). Ordinal categories are sorted as specified in the "Categories" column, or if not set, the
    default lexicographical order is used.
    <h3>Note</h3>
    Selected Numeric columns will be converted to String type, before being converted to Categorical.
</section>
<section name="ToString">
    <h2>To string</h2>
    Convert columns to String type.<br/>
    <b>Input types</b>: All<br/>
    <b>Output types</b>: String
    <h3>Table options</h3>
    Selected columns will become String columns. No options are required.
</section>
<section name="ToTimestamp">
    <h2>To datetime</h2>
    Convert columns to Datetime type.<br/>
    <b>Input types</b>: String<br/>
    <b>Output types</b>: Datetime
    <h3>Table options</h3>
    Selected columns will be converted using the format specified in the "Format" column. If this is
    not set Pandas will try to infer it. Refer to
    <a href="https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes">
        https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes
    </a> for information on how to specify format.<br/>
    <em>Example: "%Y-%m-%d %H:%M"</em> is the format of strings like: "2019-02-23 17:43".
    <h3>Error mode</h3>
    <ul>
        <li><b>Raise</b>: invalid parsing will stop the operation with an error and no column is
            changed
        </li>
        <li><b>Coerce</b>: invalid parsed dates will be set as NaT</li>
    </ul>
</section>
<section name="PickleWriter">
    <h2>Export to pickle</h2>
    Save a dataframe in a Python serialized object (pickle)<br/>
    Useful to save a dataframe without losing types information which would be lost by exporting to csv.
    <h3>Usage</h3>
    Select the dataframe to save and the file path.
</section>
</html>